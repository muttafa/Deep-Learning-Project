{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d54ab2-5de2-4499-9c4e-6b1bbac4bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6602e9-b2bc-49f1-b804-75361579d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\mucar\\Desktop\\Deep Learning Project\\CCPP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf7663e-1279-47a8-9a3d-0172dffdd26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.27\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de266938-0b85-4158-8cef-53a1678f386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:-1].values\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b7d1362-82dd-46a5-9da8-16be7540dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size= 0.3,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35216de-970f-4f35-8e6d-06424fa2dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e596c56-e5e7-4e11-840c-2d8be19066d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6,activation = \"relu\",input_dim = 4 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2cc9d3d-6b65-46ef-b99c-919dfef592ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1be95903-6e45-4cad-bc24-c53d52e6460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f373728-7ef2-4a72-86bd-e3a11b17889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer=\"adam\",loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "720cef66-0ca0-4106-a144-365a247ee329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "210/210 [==============================] - 1s 778us/step - loss: 31659.1387\n",
      "Epoch 2/100\n",
      "210/210 [==============================] - 0s 721us/step - loss: 91.4651\n",
      "Epoch 3/100\n",
      "210/210 [==============================] - 0s 703us/step - loss: 89.5325\n",
      "Epoch 4/100\n",
      "210/210 [==============================] - 0s 725us/step - loss: 86.9787\n",
      "Epoch 5/100\n",
      "210/210 [==============================] - 0s 701us/step - loss: 83.9902\n",
      "Epoch 6/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 80.7419\n",
      "Epoch 7/100\n",
      "210/210 [==============================] - 0s 706us/step - loss: 77.2248\n",
      "Epoch 8/100\n",
      "210/210 [==============================] - 0s 719us/step - loss: 73.6465\n",
      "Epoch 9/100\n",
      "210/210 [==============================] - 0s 740us/step - loss: 69.8898\n",
      "Epoch 10/100\n",
      "210/210 [==============================] - 0s 761us/step - loss: 66.1889\n",
      "Epoch 11/100\n",
      "210/210 [==============================] - 0s 752us/step - loss: 62.4836\n",
      "Epoch 12/100\n",
      "210/210 [==============================] - 0s 708us/step - loss: 58.8353\n",
      "Epoch 13/100\n",
      "210/210 [==============================] - 0s 773us/step - loss: 55.5781\n",
      "Epoch 14/100\n",
      "210/210 [==============================] - 0s 701us/step - loss: 52.3195\n",
      "Epoch 15/100\n",
      "210/210 [==============================] - 0s 697us/step - loss: 49.5993\n",
      "Epoch 16/100\n",
      "210/210 [==============================] - 0s 706us/step - loss: 47.0207\n",
      "Epoch 17/100\n",
      "210/210 [==============================] - 0s 706us/step - loss: 44.8069\n",
      "Epoch 18/100\n",
      "210/210 [==============================] - 0s 698us/step - loss: 42.6069\n",
      "Epoch 19/100\n",
      "210/210 [==============================] - 0s 678us/step - loss: 40.9434\n",
      "Epoch 20/100\n",
      "210/210 [==============================] - 0s 782us/step - loss: 39.4437\n",
      "Epoch 21/100\n",
      "210/210 [==============================] - 0s 814us/step - loss: 38.1848\n",
      "Epoch 22/100\n",
      "210/210 [==============================] - 0s 699us/step - loss: 36.9387\n",
      "Epoch 23/100\n",
      "210/210 [==============================] - 0s 682us/step - loss: 35.9785\n",
      "Epoch 24/100\n",
      "210/210 [==============================] - 0s 688us/step - loss: 35.3272\n",
      "Epoch 25/100\n",
      "210/210 [==============================] - 0s 698us/step - loss: 34.2057\n",
      "Epoch 26/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 33.2741\n",
      "Epoch 27/100\n",
      "210/210 [==============================] - 0s 682us/step - loss: 33.2076\n",
      "Epoch 28/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 31.9403\n",
      "Epoch 29/100\n",
      "210/210 [==============================] - 0s 687us/step - loss: 31.4582\n",
      "Epoch 30/100\n",
      "210/210 [==============================] - 0s 696us/step - loss: 31.2295\n",
      "Epoch 31/100\n",
      "210/210 [==============================] - 0s 678us/step - loss: 31.3074\n",
      "Epoch 32/100\n",
      "210/210 [==============================] - 0s 745us/step - loss: 30.1781\n",
      "Epoch 33/100\n",
      "210/210 [==============================] - 0s 706us/step - loss: 29.4783\n",
      "Epoch 34/100\n",
      "210/210 [==============================] - 0s 749us/step - loss: 29.5551\n",
      "Epoch 35/100\n",
      "210/210 [==============================] - 0s 758us/step - loss: 28.9487\n",
      "Epoch 36/100\n",
      "210/210 [==============================] - 0s 668us/step - loss: 29.1096\n",
      "Epoch 37/100\n",
      "210/210 [==============================] - 0s 683us/step - loss: 28.4777\n",
      "Epoch 38/100\n",
      "210/210 [==============================] - 0s 682us/step - loss: 28.1081\n",
      "Epoch 39/100\n",
      "210/210 [==============================] - 0s 696us/step - loss: 28.3934\n",
      "Epoch 40/100\n",
      "210/210 [==============================] - 0s 682us/step - loss: 28.1546\n",
      "Epoch 41/100\n",
      "210/210 [==============================] - 0s 697us/step - loss: 28.0193\n",
      "Epoch 42/100\n",
      "210/210 [==============================] - 0s 687us/step - loss: 27.8521\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - 0s 747us/step - loss: 27.3664\n",
      "Epoch 44/100\n",
      "210/210 [==============================] - 0s 740us/step - loss: 27.6856\n",
      "Epoch 45/100\n",
      "210/210 [==============================] - 0s 769us/step - loss: 28.1556\n",
      "Epoch 46/100\n",
      "210/210 [==============================] - 0s 711us/step - loss: 27.3524\n",
      "Epoch 47/100\n",
      "210/210 [==============================] - 0s 721us/step - loss: 28.4593\n",
      "Epoch 48/100\n",
      "210/210 [==============================] - 0s 749us/step - loss: 26.9379\n",
      "Epoch 49/100\n",
      "210/210 [==============================] - 0s 740us/step - loss: 27.1929\n",
      "Epoch 50/100\n",
      "210/210 [==============================] - 0s 760us/step - loss: 27.4466\n",
      "Epoch 51/100\n",
      "210/210 [==============================] - 0s 754us/step - loss: 27.2178\n",
      "Epoch 52/100\n",
      "210/210 [==============================] - 0s 721us/step - loss: 27.2364\n",
      "Epoch 53/100\n",
      "210/210 [==============================] - 0s 784us/step - loss: 28.3133\n",
      "Epoch 54/100\n",
      "210/210 [==============================] - 0s 935us/step - loss: 27.6846\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - 0s 883us/step - loss: 27.1749\n",
      "Epoch 56/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 27.0446\n",
      "Epoch 57/100\n",
      "210/210 [==============================] - 0s 749us/step - loss: 27.6992\n",
      "Epoch 58/100\n",
      "210/210 [==============================] - 0s 802us/step - loss: 27.6869\n",
      "Epoch 59/100\n",
      "210/210 [==============================] - 0s 806us/step - loss: 26.9494\n",
      "Epoch 60/100\n",
      "210/210 [==============================] - 0s 811us/step - loss: 27.6310\n",
      "Epoch 61/100\n",
      "210/210 [==============================] - 0s 806us/step - loss: 27.3987\n",
      "Epoch 62/100\n",
      "210/210 [==============================] - 0s 843us/step - loss: 27.5068\n",
      "Epoch 63/100\n",
      "210/210 [==============================] - 0s 805us/step - loss: 27.4330\n",
      "Epoch 64/100\n",
      "210/210 [==============================] - 0s 902us/step - loss: 27.1068\n",
      "Epoch 65/100\n",
      "210/210 [==============================] - 0s 940us/step - loss: 27.2660\n",
      "Epoch 66/100\n",
      "210/210 [==============================] - 0s 802us/step - loss: 27.7544\n",
      "Epoch 67/100\n",
      "210/210 [==============================] - 0s 878us/step - loss: 26.4303\n",
      "Epoch 68/100\n",
      "210/210 [==============================] - 0s 940us/step - loss: 28.6203\n",
      "Epoch 69/100\n",
      "210/210 [==============================] - 0s 964us/step - loss: 26.8253\n",
      "Epoch 70/100\n",
      "210/210 [==============================] - 0s 852us/step - loss: 26.9686\n",
      "Epoch 71/100\n",
      "210/210 [==============================] - 0s 694us/step - loss: 27.7036\n",
      "Epoch 72/100\n",
      "210/210 [==============================] - 0s 664us/step - loss: 28.1268\n",
      "Epoch 73/100\n",
      "210/210 [==============================] - 0s 678us/step - loss: 27.2227\n",
      "Epoch 74/100\n",
      "210/210 [==============================] - 0s 682us/step - loss: 27.5087\n",
      "Epoch 75/100\n",
      "210/210 [==============================] - 0s 682us/step - loss: 27.3985\n",
      "Epoch 76/100\n",
      "210/210 [==============================] - 0s 711us/step - loss: 27.7914\n",
      "Epoch 77/100\n",
      "210/210 [==============================] - 0s 973us/step - loss: 27.1609\n",
      "Epoch 78/100\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 27.8694\n",
      "Epoch 79/100\n",
      "210/210 [==============================] - 0s 919us/step - loss: 27.0212\n",
      "Epoch 80/100\n",
      "210/210 [==============================] - 0s 989us/step - loss: 27.0851\n",
      "Epoch 81/100\n",
      "210/210 [==============================] - 0s 925us/step - loss: 26.7738\n",
      "Epoch 82/100\n",
      "210/210 [==============================] - 0s 738us/step - loss: 26.5935\n",
      "Epoch 83/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 27.9620\n",
      "Epoch 84/100\n",
      "210/210 [==============================] - 0s 749us/step - loss: 27.4909\n",
      "Epoch 85/100\n",
      "210/210 [==============================] - 0s 687us/step - loss: 28.0049\n",
      "Epoch 86/100\n",
      "210/210 [==============================] - 0s 682us/step - loss: 27.1350\n",
      "Epoch 87/100\n",
      "210/210 [==============================] - 0s 711us/step - loss: 26.7263\n",
      "Epoch 88/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 27.6173\n",
      "Epoch 89/100\n",
      "210/210 [==============================] - 0s 771us/step - loss: 26.9048\n",
      "Epoch 90/100\n",
      "210/210 [==============================] - 0s 716us/step - loss: 27.5001\n",
      "Epoch 91/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 29.0572\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - 0s 683us/step - loss: 27.0710\n",
      "Epoch 93/100\n",
      "210/210 [==============================] - 0s 682us/step - loss: 28.0703\n",
      "Epoch 94/100\n",
      "210/210 [==============================] - 0s 689us/step - loss: 27.2480\n",
      "Epoch 95/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 26.7625\n",
      "Epoch 96/100\n",
      "210/210 [==============================] - 0s 692us/step - loss: 26.8776\n",
      "Epoch 97/100\n",
      "210/210 [==============================] - 0s 677us/step - loss: 26.6945\n",
      "Epoch 98/100\n",
      "210/210 [==============================] - 0s 687us/step - loss: 26.8422\n",
      "Epoch 99/100\n",
      "210/210 [==============================] - 0s 711us/step - loss: 26.7438\n",
      "Epoch 100/100\n",
      "210/210 [==============================] - 0s 795us/step - loss: 27.5570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159e9242130>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(x_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0a80d1c-c2c1-441a-a247-48e53a2b5a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 549us/step\n"
     ]
    }
   ],
   "source": [
    "ypred = ann.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66857b8d-b984-4ab3-82a5-ddcb08852658",
   "metadata": {},
   "outputs": [],
   "source": [
    "ylist= list(y)\n",
    "y_data[\"y_original\"] = pd.DataFrame(ylist)\n",
    "y_data[\"ypredict\"] = pd.DataFrame(list(ypred))\n",
    "\n",
    "\n",
    "y_data = y_data.drop(0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23580045-f2f0-4535-b68e-9c64d1df5608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ypredict</th>\n",
       "      <th>y_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454.712341</td>\n",
       "      <td>463.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436.742432</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>431.562531</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>436.654846</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>477.990295</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>437.659973</td>\n",
       "      <td>443.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>448.751740</td>\n",
       "      <td>467.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>432.914062</td>\n",
       "      <td>478.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>430.832581</td>\n",
       "      <td>475.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>473.647858</td>\n",
       "      <td>477.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>454.144135</td>\n",
       "      <td>453.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>439.500458</td>\n",
       "      <td>453.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>466.621613</td>\n",
       "      <td>440.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>438.393158</td>\n",
       "      <td>451.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>455.397156</td>\n",
       "      <td>433.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>472.426788</td>\n",
       "      <td>462.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>473.123779</td>\n",
       "      <td>467.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>445.118713</td>\n",
       "      <td>477.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>459.495605</td>\n",
       "      <td>459.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>433.585052</td>\n",
       "      <td>464.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>478.830292</td>\n",
       "      <td>468.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>427.055939</td>\n",
       "      <td>495.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>426.763611</td>\n",
       "      <td>483.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>459.898529</td>\n",
       "      <td>443.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>450.359497</td>\n",
       "      <td>436.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>466.505219</td>\n",
       "      <td>443.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>440.045410</td>\n",
       "      <td>464.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>432.126099</td>\n",
       "      <td>475.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>464.195953</td>\n",
       "      <td>484.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>455.667084</td>\n",
       "      <td>437.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>452.698761</td>\n",
       "      <td>445.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>442.735138</td>\n",
       "      <td>438.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>473.631378</td>\n",
       "      <td>440.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>461.654968</td>\n",
       "      <td>436.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>454.484894</td>\n",
       "      <td>444.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>430.237000</td>\n",
       "      <td>465.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>447.818695</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>464.128082</td>\n",
       "      <td>450.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>454.850494</td>\n",
       "      <td>469.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>479.448090</td>\n",
       "      <td>448.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>469.621490</td>\n",
       "      <td>447.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>439.150543</td>\n",
       "      <td>469.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>429.645386</td>\n",
       "      <td>482.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>430.352936</td>\n",
       "      <td>476.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>474.521698</td>\n",
       "      <td>474.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>463.409760</td>\n",
       "      <td>444.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>436.463104</td>\n",
       "      <td>461.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>439.779236</td>\n",
       "      <td>448.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>437.335907</td>\n",
       "      <td>474.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>472.883636</td>\n",
       "      <td>473.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ypredict  y_original\n",
       "0   454.712341      463.27\n",
       "1   436.742432      444.37\n",
       "2   431.562531      488.56\n",
       "3   436.654846      446.48\n",
       "4   477.990295      473.90\n",
       "5   437.659973      443.67\n",
       "6   448.751740      467.35\n",
       "7   432.914062      478.42\n",
       "8   430.832581      475.98\n",
       "9   473.647858      477.50\n",
       "10  454.144135      453.02\n",
       "11  439.500458      453.99\n",
       "12  466.621613      440.29\n",
       "13  438.393158      451.28\n",
       "14  455.397156      433.99\n",
       "15  472.426788      462.19\n",
       "16  473.123779      467.54\n",
       "17  445.118713      477.20\n",
       "18  459.495605      459.85\n",
       "19  433.585052      464.30\n",
       "20  478.830292      468.27\n",
       "21  427.055939      495.24\n",
       "22  426.763611      483.80\n",
       "23  459.898529      443.61\n",
       "24  450.359497      436.06\n",
       "25  466.505219      443.25\n",
       "26  440.045410      464.16\n",
       "27  432.126099      475.52\n",
       "28  464.195953      484.41\n",
       "29  455.667084      437.89\n",
       "30  452.698761      445.11\n",
       "31  442.735138      438.86\n",
       "32  473.631378      440.98\n",
       "33  461.654968      436.65\n",
       "34  454.484894      444.26\n",
       "35  430.237000      465.86\n",
       "36  447.818695      444.37\n",
       "37  464.128082      450.69\n",
       "38  454.850494      469.02\n",
       "39  479.448090      448.86\n",
       "40  469.621490      447.14\n",
       "41  439.150543      469.18\n",
       "42  429.645386      482.80\n",
       "43  430.352936      476.70\n",
       "44  474.521698      474.99\n",
       "45  463.409760      444.22\n",
       "46  436.463104      461.33\n",
       "47  439.779236      448.06\n",
       "48  437.335907      474.60\n",
       "49  472.883636      473.05"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caccd491-978a-4178-98e2-91270bac419a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
